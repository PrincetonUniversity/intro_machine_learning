{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsGrgoWTZImD1zjdvDl42h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdh4/resnet50/blob/master/day5_computer_vision_hackathon_notebook3_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction to Machine Learning  \n",
        "**Computer Vision Hackathon  \n",
        "Wintersession  \n",
        "Tuesday, January 24, 2023**"
      ],
      "metadata": {
        "id": "aga1pGnHqFDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook you will use transfer learning to get a very high accuracy on the cats versus dog problem. The idea is to take a large CNN model trained on vast amounts of data and retrain only the top layers while freezing the lower layers. We are transferring the learning done previously to our problem. We will use the ResNet-50 model."
      ],
      "metadata": {
        "id": "UNycfWo7M0TV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About Your Colab Session"
      ],
      "metadata": {
        "id": "2zeUMxrssifc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn about the CPU-cores for your session:"
      ],
      "metadata": {
        "id": "DuQEJ5K4T6mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat /proc/cpuinfo"
      ],
      "metadata": {
        "id": "kmhl7u9GTJdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "num_cores = min(os.cpu_count(), 2)\n",
        "print(num_cores)"
      ],
      "metadata": {
        "id": "pvmd8gdqqadV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see which GPU we are using (probably a Tesla T4):"
      ],
      "metadata": {
        "id": "boWe_CxtT_NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8yR2en5xCqsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "wGufTwtPso3h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH3SrMfHBejx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to use a GPU when one is available:"
      ],
      "metadata": {
        "id": "OOKVq098sZne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)"
      ],
      "metadata": {
        "id": "Nk3pkXNxCF5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\") if use_cuda else torch.device(\"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': 64}\n",
        "test_kwargs  = {'batch_size': 128}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': num_cores, 'pin_memory': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)"
      ],
      "metadata": {
        "id": "TVoXo2d6CVwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and unpack the data:"
      ],
      "metadata": {
        "id": "oPIynRI6zWut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://tigress-web.princeton.edu/~jdh4/cats_vs_dogs.tar\n",
        "!tar xf cats_vs_dogs.tar"
      ],
      "metadata": {
        "id": "UbRdgWThzTcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))])\n",
        "dataset1 = datasets.ImageFolder(root=\"./training_set/\", transform=transform)\n",
        "dataset2 = datasets.ImageFolder(root=\"./test_set/\", transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset1, shuffle=True, **train_kwargs)\n",
        "test_loader  = torch.utils.data.DataLoader(dataset2, shuffle=True, **test_kwargs)"
      ],
      "metadata": {
        "id": "NgIFFS1TJp-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are roughly 4000 cat images and 4000 dog images in the training set. The test set is roughly 1000 images of each. All images have dimensions 128x128. The cat and dogs images are in color so they are composed of three layers (red, green, blue). The MNIST data set was grayscale so only a single layer was needed per image."
      ],
      "metadata": {
        "id": "NO9cdWhN4ouV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(\"./training_set/dogs/resized-dog.1001.jpg\")\n",
        "print(f\"Image height: {img.height}\") \n",
        "print(f\"Image width: {img.width}\")\n",
        "img"
      ],
      "metadata": {
        "id": "KkXNTCGY28xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(\"./training_set/cats/resized-cat.1001.jpg\")\n",
        "print(f\"Image height: {img.height}\") \n",
        "print(f\"Image width: {img.width}\")\n",
        "img"
      ],
      "metadata": {
        "id": "vPX6m50p3laY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "NxvDfF0Ps9uZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below the model is downloaded. We turn-off gradient tracking for all model parameters except the last two linear layers. The model is moved to the device (which is a GPU is available) and the optimizer is created."
      ],
      "metadata": {
        "id": "QVGbz36OuS8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(weights='DEFAULT')\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# use print(model) to see that the name of the last layer is fc\n",
        "# we redefine fc in the next line\n",
        "model.fc = nn.Sequential(nn.Linear(2048, 128), nn.ReLU(inplace=True), nn.Linear(128, 2))\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adadelta(model.fc.parameters(), lr=1.0)"
      ],
      "metadata": {
        "id": "tvkGwJD_JGEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, input_size=(3, 128, 128))"
      ],
      "metadata": {
        "id": "kTfbe4QKRYLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Test Methods"
      ],
      "metadata": {
        "id": "KYR03y9dvDEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train() # sets the model in training mode (i.e., dropout enabled)\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(F.log_softmax(output, dim=1), target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "metadata": {
        "id": "_PrPJRlsCCO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval() # sets the model in evaluation mode (i.e., dropout disabled)\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "bns0Q8O-CFVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train for some number of epochs while reporting the accuracy on the test set periodically:"
      ],
      "metadata": {
        "id": "2Zxo7USTvKMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 12\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "Yl8Lcz1RJCk9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}