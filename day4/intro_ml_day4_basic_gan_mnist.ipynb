{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generating MNIST Digits w/ Generative Adversarial Networks\n",
        "\n",
        "Introduction to Machine Learning (Day 4)\\\n",
        "Princeton University Wintersession\\\n",
        "Gage DeZoort and Jon Halverson\\\n",
        "\\\n",
        "Based on [this GAN tutorial](https://https://www.kaggle.com/code/songseungwon/pytorch-gan-basic-tutorial-for-beginner) on Kaggle."
      ],
      "metadata": {
        "id": "megx9P2Vvskc"
      },
      "id": "megx9P2Vvskc"
    },
    {
      "cell_type": "markdown",
      "id": "fiscal-publicity",
      "metadata": {
        "papermill": {
          "duration": 0.066405,
          "end_time": "2021-06-23T15:56:59.994924",
          "exception": false,
          "start_time": "2021-06-23T15:56:59.928519",
          "status": "completed"
        },
        "tags": [],
        "id": "fiscal-publicity"
      },
      "source": [
        "# Generative Adversarial Networks(GAN) - PyTorch Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "running-skating",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:52:00.243235Z",
          "iopub.status.busy": "2021-06-23T15:52:00.242873Z",
          "iopub.status.idle": "2021-06-23T15:52:00.880086Z",
          "shell.execute_reply": "2021-06-23T15:52:00.879121Z",
          "shell.execute_reply.started": "2021-06-23T15:52:00.243159Z"
        },
        "papermill": {
          "duration": 0.047088,
          "end_time": "2021-06-23T15:57:00.102789",
          "exception": false,
          "start_time": "2021-06-23T15:57:00.055701",
          "status": "completed"
        },
        "tags": [],
        "id": "running-skating"
      },
      "source": [
        "![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHwq72%2FbtqAY6E0wYb%2FBFRgtJWTY3Ij9BKks7vsM1%2Fimg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "saving-chain",
      "metadata": {
        "papermill": {
          "duration": 0.058304,
          "end_time": "2021-06-23T15:57:00.232764",
          "exception": false,
          "start_time": "2021-06-23T15:57:00.174460",
          "status": "completed"
        },
        "tags": [],
        "id": "saving-chain"
      },
      "source": [
        "\n",
        "Generative Adversarial Networks (GANs) are generative models, meaning they're designed to produce new data. The working principle is simple: two neural networks networks (the Generator and Discriminator) with competing objectives are trained against each other. The generator's goal is to produce realistic data, while the discriminator's goal is to decide whether data is fake (created by the generator) or real (belonging to the training/test set)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "italian-ordinance",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T13:11:22.760936Z",
          "iopub.status.busy": "2021-06-12T13:11:22.760514Z",
          "iopub.status.idle": "2021-06-12T13:11:22.773432Z",
          "shell.execute_reply": "2021-06-12T13:11:22.771815Z",
          "shell.execute_reply.started": "2021-06-12T13:11:22.760902Z"
        },
        "papermill": {
          "duration": 0.046821,
          "end_time": "2021-06-23T15:57:00.326810",
          "exception": false,
          "start_time": "2021-06-23T15:57:00.279989",
          "status": "completed"
        },
        "tags": [],
        "id": "italian-ordinance"
      },
      "source": [
        "Several implementations of the GAN are available here: [PyTorch-GAN | Github/eriklindernoren | Collection of PyTorch implementations of GAN](https://github.com/sw-song/PyTorch-GAN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "working-escape",
      "metadata": {
        "papermill": {
          "duration": 0.045072,
          "end_time": "2021-06-23T15:57:00.417804",
          "exception": false,
          "start_time": "2021-06-23T15:57:00.372732",
          "status": "completed"
        },
        "tags": [],
        "id": "working-escape"
      },
      "source": [
        "## Index\n",
        "Here's a quick look at what we'll be doing:\n",
        "```\n",
        "Step 1. Import Libraries\n",
        "Step 2. Initial Setting\n",
        "Step 3. Define Generator\n",
        "Step 4. Define Discriminator\n",
        "Step 5. Define Loss Function\n",
        "Step 6. Initialize Generator and Discriminator\n",
        "Step 7. GPU Setting\n",
        "Step 8. Configure Data Loader\n",
        "Step 9. Define Optimizers\n",
        "Step 10. Training\n",
        "```\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "limited-eligibility",
      "metadata": {
        "papermill": {
          "duration": 0.045384,
          "end_time": "2021-06-23T15:57:00.508717",
          "exception": false,
          "start_time": "2021-06-23T15:57:00.463333",
          "status": "completed"
        },
        "tags": [],
        "id": "limited-eligibility"
      },
      "source": [
        "### Step 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "touched-phase",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:00.611183Z",
          "iopub.status.busy": "2021-06-23T15:57:00.610471Z",
          "iopub.status.idle": "2021-06-23T15:57:02.113220Z",
          "shell.execute_reply": "2021-06-23T15:57:02.114347Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.767977Z"
        },
        "papermill": {
          "duration": 1.560143,
          "end_time": "2021-06-23T15:57:02.114682",
          "exception": false,
          "start_time": "2021-06-23T15:57:00.554539",
          "status": "completed"
        },
        "tags": [],
        "id": "touched-phase"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-bullet",
      "metadata": {
        "papermill": {
          "duration": 0.058773,
          "end_time": "2021-06-23T15:57:02.254010",
          "exception": false,
          "start_time": "2021-06-23T15:57:02.195237",
          "status": "completed"
        },
        "tags": [],
        "id": "dramatic-bullet"
      },
      "source": [
        "### Step 2. Initial setting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to be analyzing the MNIST images again; recall that they're 28x28 greyscale images (i.e. one feature dimension per pixel)."
      ],
      "metadata": {
        "id": "w7e87dGfuTSY"
      },
      "id": "w7e87dGfuTSY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "czech-bahrain",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:02.350107Z",
          "iopub.status.busy": "2021-06-23T15:57:02.349187Z",
          "iopub.status.idle": "2021-06-23T15:57:02.351947Z",
          "shell.execute_reply": "2021-06-23T15:57:02.351430Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.774368Z"
        },
        "papermill": {
          "duration": 0.052084,
          "end_time": "2021-06-23T15:57:02.352056",
          "exception": false,
          "start_time": "2021-06-23T15:57:02.299972",
          "status": "completed"
        },
        "tags": [],
        "id": "czech-bahrain"
      },
      "outputs": [],
      "source": [
        "channels = 1 # 1, number of image channels (gray scale)\n",
        "img_size = 28 # 28, size of each image dimension\n",
        "img_shape = (channels, img_size, img_size) # (channels, image height, image width)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a graphic to show what exactly we're going to code up:\n",
        "\n",
        "![GAN](https://developers.google.com/machine-learning/gan/images/gan_diagram.svg \"gan\")\n",
        "\n",
        "The generator is going to generate images based on 100 random noise inputs. You can think about these noise inputs as \"instructions\" for the type of image to be generated."
      ],
      "metadata": {
        "id": "F7i-HA2MvDfK"
      },
      "id": "F7i-HA2MvDfK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "democratic-magic",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:02.446628Z",
          "iopub.status.busy": "2021-06-23T15:57:02.446128Z",
          "iopub.status.idle": "2021-06-23T15:57:02.449933Z",
          "shell.execute_reply": "2021-06-23T15:57:02.449517Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.790593Z"
        },
        "papermill": {
          "duration": 0.052767,
          "end_time": "2021-06-23T15:57:02.450049",
          "exception": false,
          "start_time": "2021-06-23T15:57:02.397282",
          "status": "completed"
        },
        "tags": [],
        "id": "democratic-magic"
      },
      "outputs": [],
      "source": [
        "latent_dim = 100 # dimensionality"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last, let's make sure we can talk to the GPU:"
      ],
      "metadata": {
        "id": "a-mG8x-OwQNr"
      },
      "id": "a-mG8x-OwQNr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "olive-driving",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:02.588494Z",
          "iopub.status.busy": "2021-06-23T15:57:02.587765Z",
          "iopub.status.idle": "2021-06-23T15:57:02.591612Z",
          "shell.execute_reply": "2021-06-23T15:57:02.590802Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.798688Z"
        },
        "papermill": {
          "duration": 0.09587,
          "end_time": "2021-06-23T15:57:02.591735",
          "exception": false,
          "start_time": "2021-06-23T15:57:02.495865",
          "status": "completed"
        },
        "tags": [],
        "id": "olive-driving"
      },
      "outputs": [],
      "source": [
        "cuda = True if torch.cuda.is_available() else False # GPU Setting\n",
        "print(cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "compressed-employer",
      "metadata": {
        "papermill": {
          "duration": 0.044867,
          "end_time": "2021-06-23T15:57:02.682618",
          "exception": false,
          "start_time": "2021-06-23T15:57:02.637751",
          "status": "completed"
        },
        "tags": [],
        "id": "compressed-employer"
      },
      "source": [
        "### Step 3. Define Generator\n",
        "\n",
        "With out initial dimensions taken care of, we'll turn to defining a generator module. We're not going to break out the heavy CNN machinery; instead we'll try to generate flattened MNIST digits using a standard feed-forward deep NN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "random-colorado",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:02.782455Z",
          "iopub.status.busy": "2021-06-23T15:57:02.781610Z",
          "iopub.status.idle": "2021-06-23T15:57:02.784207Z",
          "shell.execute_reply": "2021-06-23T15:57:02.783774Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.806487Z"
        },
        "papermill": {
          "duration": 0.056433,
          "end_time": "2021-06-23T15:57:02.784323",
          "exception": false,
          "start_time": "2021-06-23T15:57:02.727890",
          "status": "completed"
        },
        "tags": [],
        "id": "random-colorado"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # each block is a combination of (Linear, LeakyReLU)\n",
        "        def block(input_features, output_features, normalize=True):\n",
        "            layers = [nn.Linear(input_features, output_features)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(output_features, 0.8))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers # return list of layers\n",
        "\n",
        "        # DNN: 100->128->256->512->1024->784 (flattened 28x28 image)\n",
        "        self.model = nn.Sequential(\n",
        "            *block(latent_dim, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, img_size**2), # produce 28x28=784 dimensional outputs\n",
        "            nn.Tanh() # result : from -1 to 1\n",
        "        )\n",
        "\n",
        "    # input z (latent vector) containing random variables\n",
        "    def forward(self, z):\n",
        "        img = self.model(z) # (batch_size, 100) -> (batch_size, 784)\n",
        "        img = img.view(img.size(0), *img_shape) # img.size(0) == batch_size\n",
        "        return img"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EXERCISE 1**\n",
        "\n",
        "(2 mins) Try instantiating a generator. Print it out and study the dimensions. Do they make sense? What is the dimension of the output of the generator?"
      ],
      "metadata": {
        "id": "VNx1kbfTAFIy"
      },
      "id": "VNx1kbfTAFIy"
    },
    {
      "cell_type": "code",
      "source": [
        "# study the generator\n",
        "g = Generator()\n",
        "\n",
        "# latent variables to feed the generator\n",
        "g.eval()\n",
        "z = torch.normal(mean=0, std=1, size=(1,100))"
      ],
      "metadata": {
        "id": "zxk-HXB8AT8V"
      },
      "id": "zxk-HXB8AT8V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "subject-furniture",
      "metadata": {
        "papermill": {
          "duration": 0.046588,
          "end_time": "2021-06-23T15:57:02.876852",
          "exception": false,
          "start_time": "2021-06-23T15:57:02.830264",
          "status": "completed"
        },
        "tags": [],
        "id": "subject-furniture"
      },
      "source": [
        "> Read More\n",
        "- [BatchNorm1d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html)\n",
        "- [Tanh](https://wiki.documentfoundation.org/Documentation/Calc_Functions/TANH)\n",
        "- [Unpacking Operators in Python](https://towardsdatascience.com/unpacking-operators-in-python-306ae44cd480)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "familiar-situation",
      "metadata": {
        "papermill": {
          "duration": 0.045691,
          "end_time": "2021-06-23T15:57:02.968902",
          "exception": false,
          "start_time": "2021-06-23T15:57:02.923211",
          "status": "completed"
        },
        "tags": [],
        "id": "familiar-situation"
      },
      "source": [
        "### Step 4. Define Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "objective-syndicate",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:03.066394Z",
          "iopub.status.busy": "2021-06-23T15:57:03.065562Z",
          "iopub.status.idle": "2021-06-23T15:57:03.067715Z",
          "shell.execute_reply": "2021-06-23T15:57:03.068159Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.817193Z"
        },
        "papermill": {
          "duration": 0.054014,
          "end_time": "2021-06-23T15:57:03.068291",
          "exception": false,
          "start_time": "2021-06-23T15:57:03.014277",
          "status": "completed"
        },
        "tags": [],
        "id": "objective-syndicate"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # DNN: 784->512->256->1 dimensions\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(img_size**2, 512), # (28*28, 512)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid() # normalize output into range [0,1]\n",
        "        )\n",
        "\n",
        "    # input image from generator or discriminator\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1) #flatten -> from (64, 1, 28, 28) to (64, 1*28*28)\n",
        "        validity = self.model(img_flat) # (64, 784) -> (64, 1), real vs. fake prediction\n",
        "        return validity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EXERCISE 2**\n",
        "\n",
        "(2 mins) Try instantiating a discriminator. Print it out and study the dimensions. Do they make sense? What is the dimension of the output of the discriminator?"
      ],
      "metadata": {
        "id": "wIp6TFuTCpee"
      },
      "id": "wIp6TFuTCpee"
    },
    {
      "cell_type": "code",
      "source": [
        "# study the generator\n",
        "d = Discriminator()\n",
        "print(d)\n",
        "\n",
        "# latent variables to feed the generator\n",
        "d.eval()\n",
        "img = torch.normal(mean=0, std=1, size=(1,1,28,28))\n",
        "pred = d(img)\n",
        "print(pred, pred.shape)"
      ],
      "metadata": {
        "id": "UWGnHJErC9dA"
      },
      "id": "UWGnHJErC9dA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "complicated-macintosh",
      "metadata": {
        "papermill": {
          "duration": 0.045784,
          "end_time": "2021-06-23T15:57:03.251043",
          "exception": false,
          "start_time": "2021-06-23T15:57:03.205259",
          "status": "completed"
        },
        "tags": [],
        "id": "complicated-macintosh"
      },
      "source": [
        "### Step 5. Define Loss Function\n",
        "\n",
        "Our loss function will compare the Discriminator's predictions to ground truth. Real images will be assigned `1` and fake images `0`. The output of the discriminator will be some number in the range `(0,1)` for each image. We'll use binary cross entropy (BCE) to compare the predicted probabilities to the targets; check out the [BCELoss PyTorch docs](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html) if you'd like to learn more about it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "written-somalia",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:03.347106Z",
          "iopub.status.busy": "2021-06-23T15:57:03.345816Z",
          "iopub.status.idle": "2021-06-23T15:57:03.348025Z",
          "shell.execute_reply": "2021-06-23T15:57:03.348497Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.829386Z"
        },
        "papermill": {
          "duration": 0.052019,
          "end_time": "2021-06-23T15:57:03.348632",
          "exception": false,
          "start_time": "2021-06-23T15:57:03.296613",
          "status": "completed"
        },
        "tags": [],
        "id": "written-somalia"
      },
      "outputs": [],
      "source": [
        "adversarial_loss = torch.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "selective-lloyd",
      "metadata": {
        "papermill": {
          "duration": 0.044943,
          "end_time": "2021-06-23T15:57:03.438981",
          "exception": false,
          "start_time": "2021-06-23T15:57:03.394038",
          "status": "completed"
        },
        "tags": [],
        "id": "selective-lloyd"
      },
      "source": [
        "> Read More\n",
        "- [BCELoss(Binary Cross Entropy Loss)](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "supreme-massage",
      "metadata": {
        "papermill": {
          "duration": 0.045278,
          "end_time": "2021-06-23T15:57:03.529404",
          "exception": false,
          "start_time": "2021-06-23T15:57:03.484126",
          "status": "completed"
        },
        "tags": [],
        "id": "supreme-massage"
      },
      "source": [
        "### Step 6. Initialize Generator and Discriminator\n",
        "\n",
        "Let's instantiate a Generator and Discriminator and double-check what they're made of.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "disciplinary-guitar",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:03.625788Z",
          "iopub.status.busy": "2021-06-23T15:57:03.625261Z",
          "iopub.status.idle": "2021-06-23T15:57:03.672743Z",
          "shell.execute_reply": "2021-06-23T15:57:03.672285Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.837328Z"
        },
        "papermill": {
          "duration": 0.097554,
          "end_time": "2021-06-23T15:57:03.672851",
          "exception": false,
          "start_time": "2021-06-23T15:57:03.575297",
          "status": "completed"
        },
        "tags": [],
        "id": "disciplinary-guitar"
      },
      "outputs": [],
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "matched-glory",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:03.771613Z",
          "iopub.status.busy": "2021-06-23T15:57:03.771096Z",
          "iopub.status.idle": "2021-06-23T15:57:03.776993Z",
          "shell.execute_reply": "2021-06-23T15:57:03.776590Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.886549Z"
        },
        "papermill": {
          "duration": 0.058138,
          "end_time": "2021-06-23T15:57:03.777110",
          "exception": false,
          "start_time": "2021-06-23T15:57:03.718972",
          "status": "completed"
        },
        "tags": [],
        "id": "matched-glory"
      },
      "outputs": [],
      "source": [
        "generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fewer-wilson",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:03.873395Z",
          "iopub.status.busy": "2021-06-23T15:57:03.872652Z",
          "iopub.status.idle": "2021-06-23T15:57:03.876145Z",
          "shell.execute_reply": "2021-06-23T15:57:03.875736Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.893087Z"
        },
        "papermill": {
          "duration": 0.053415,
          "end_time": "2021-06-23T15:57:03.876259",
          "exception": false,
          "start_time": "2021-06-23T15:57:03.822844",
          "status": "completed"
        },
        "tags": [],
        "id": "fewer-wilson"
      },
      "outputs": [],
      "source": [
        "discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "suitable-panama",
      "metadata": {
        "papermill": {
          "duration": 0.045553,
          "end_time": "2021-06-23T15:57:03.968175",
          "exception": false,
          "start_time": "2021-06-23T15:57:03.922622",
          "status": "completed"
        },
        "tags": [],
        "id": "suitable-panama"
      },
      "source": [
        "### Step 7. GPU Setting\n",
        "Ship everything off to the GPU!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "radical-paraguay",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:04.068403Z",
          "iopub.status.busy": "2021-06-23T15:57:04.067666Z",
          "iopub.status.idle": "2021-06-23T15:57:08.470553Z",
          "shell.execute_reply": "2021-06-23T15:57:08.470110Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.905437Z"
        },
        "papermill": {
          "duration": 4.456583,
          "end_time": "2021-06-23T15:57:08.470678",
          "exception": false,
          "start_time": "2021-06-23T15:57:04.014095",
          "status": "completed"
        },
        "tags": [],
        "id": "radical-paraguay"
      },
      "outputs": [],
      "source": [
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "distributed-subcommittee",
      "metadata": {
        "papermill": {
          "duration": 0.046577,
          "end_time": "2021-06-23T15:57:08.564572",
          "exception": false,
          "start_time": "2021-06-23T15:57:08.517995",
          "status": "completed"
        },
        "tags": [],
        "id": "distributed-subcommittee"
      },
      "source": [
        "### Step 8. Configure Data Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dried-quarter",
      "metadata": {
        "papermill": {
          "duration": 0.045862,
          "end_time": "2021-06-23T15:57:08.656938",
          "exception": false,
          "start_time": "2021-06-23T15:57:08.611076",
          "status": "completed"
        },
        "tags": [],
        "id": "dried-quarter"
      },
      "source": [
        "This tutorial grabs MNIST from Kaggle. We'll use a `DatasetMNIST` class to load it up; the details aren't super improtant. We'll then use the [Pytorch Dataset and DataLoader](https://www.kaggle.com/pinocookie/pytorch-dataset-and-dataloader) to produce batches of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "personalized-positive",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:08.754356Z",
          "iopub.status.busy": "2021-06-23T15:57:08.752966Z",
          "iopub.status.idle": "2021-06-23T15:57:08.755497Z",
          "shell.execute_reply": "2021-06-23T15:57:08.755921Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.916768Z"
        },
        "papermill": {
          "duration": 0.052988,
          "end_time": "2021-06-23T15:57:08.756055",
          "exception": false,
          "start_time": "2021-06-23T15:57:08.703067",
          "status": "completed"
        },
        "tags": [],
        "id": "personalized-positive"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "placed-stroke",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:08.856128Z",
          "iopub.status.busy": "2021-06-23T15:57:08.855252Z",
          "iopub.status.idle": "2021-06-23T15:57:08.857804Z",
          "shell.execute_reply": "2021-06-23T15:57:08.857416Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.922514Z"
        },
        "papermill": {
          "duration": 0.055687,
          "end_time": "2021-06-23T15:57:08.857927",
          "exception": false,
          "start_time": "2021-06-23T15:57:08.802240",
          "status": "completed"
        },
        "tags": [],
        "id": "placed-stroke"
      },
      "outputs": [],
      "source": [
        "class DatasetMNIST(Dataset):\n",
        "    def __init__(self, file_path, transform=None):\n",
        "        self.data = pd.read_csv(file_path)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((28,28,1))\n",
        "        label = self.data.iloc[index, 0]\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "massive-temperature",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:09.051423Z",
          "iopub.status.busy": "2021-06-23T15:57:09.050848Z",
          "iopub.status.idle": "2021-06-23T15:57:11.996080Z",
          "shell.execute_reply": "2021-06-23T15:57:11.995199Z",
          "shell.execute_reply.started": "2021-06-14T10:50:34.932828Z"
        },
        "papermill": {
          "duration": 2.999481,
          "end_time": "2021-06-23T15:57:11.996219",
          "exception": false,
          "start_time": "2021-06-23T15:57:08.996738",
          "status": "completed"
        },
        "tags": [],
        "id": "massive-temperature"
      },
      "outputs": [],
      "source": [
        "# train.csv is 74 MB\n",
        "# data taken from https://www.kaggle.com/code/songseungwon/pytorch-gan-basic-tutorial-for-beginner/input\n",
        "train = pd.read_csv('https://tigress-web.princeton.edu/~jdh4/intro_ml/gan/train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous cell, we loaded up the dataset as a `Pandas` dataframe. We can take a look at the dataset in the cell below. You should find that each row corresponds to an image. The columns correspond to the truth label for the image, then every one of the 784 pixel values."
      ],
      "metadata": {
        "id": "EFLmWTon0o7t"
      },
      "id": "EFLmWTon0o7t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "christian-population",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:12.097861Z",
          "iopub.status.busy": "2021-06-23T15:57:12.097079Z",
          "iopub.status.idle": "2021-06-23T15:57:12.121115Z",
          "shell.execute_reply": "2021-06-23T15:57:12.121511Z",
          "shell.execute_reply.started": "2021-06-14T10:50:36.997167Z"
        },
        "papermill": {
          "duration": 0.07898,
          "end_time": "2021-06-23T15:57:12.121642",
          "exception": false,
          "start_time": "2021-06-23T15:57:12.042662",
          "status": "completed"
        },
        "tags": [],
        "id": "christian-population"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Digging into the `DatasetMNIST` class, we can check for 5 images that the `__getitem__` function does indeed load images in the correct shape."
      ],
      "metadata": {
        "id": "q8sc5t9X1BRy"
      },
      "id": "q8sc5t9X1BRy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "civil-dependence",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:12.317113Z",
          "iopub.status.busy": "2021-06-23T15:57:12.316269Z",
          "iopub.status.idle": "2021-06-23T15:57:12.321454Z",
          "shell.execute_reply": "2021-06-23T15:57:12.322067Z",
          "shell.execute_reply.started": "2021-06-14T10:50:37.022833Z"
        },
        "papermill": {
          "duration": 0.06019,
          "end_time": "2021-06-23T15:57:12.322293",
          "exception": false,
          "start_time": "2021-06-23T15:57:12.262103",
          "status": "completed"
        },
        "tags": [],
        "id": "civil-dependence"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "for index in range(1, 6): # N : 5 (Number of Image)\n",
        "    temp_image = train.iloc[index, 1:].values.astype(np.uint8).reshape((28,28,1))\n",
        "    temp_label = train.iloc[index, 0]\n",
        "    print('Shape of Image : ',temp_image.shape)\n",
        "    print('label : ', temp_label)\n",
        "    imshow(temp_image, cmap='gray', vmin=0, vmax=255)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "signal-clinic",
      "metadata": {
        "papermill": {
          "duration": 0.047268,
          "end_time": "2021-06-23T15:57:12.417044",
          "exception": false,
          "start_time": "2021-06-23T15:57:12.369776",
          "status": "completed"
        },
        "tags": [],
        "id": "signal-clinic"
      },
      "source": [
        "Okay, good, we have images. Let's load them up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hundred-arizona",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:12.517266Z",
          "iopub.status.busy": "2021-06-23T15:57:12.516470Z",
          "iopub.status.idle": "2021-06-23T15:57:14.738901Z",
          "shell.execute_reply": "2021-06-23T15:57:14.738465Z",
          "shell.execute_reply.started": "2021-06-14T10:50:37.035911Z"
        },
        "papermill": {
          "duration": 2.275176,
          "end_time": "2021-06-23T15:57:14.739073",
          "exception": false,
          "start_time": "2021-06-23T15:57:12.463897",
          "status": "completed"
        },
        "tags": [],
        "id": "hundred-arizona"
      },
      "outputs": [],
      "source": [
        "dataset = DatasetMNIST(\n",
        "  file_path='https://tigress-web.princeton.edu/~jdh4/intro_ml/gan/train.csv',\n",
        "  transform=transforms.Compose(\n",
        "    [\n",
        "    transforms.ToTensor(), # ensures shape is (channels, height, width)\n",
        "    transforms.Normalize([0.5],[0.5]) # normalize images to range [-1, 1]\n",
        "    ]\n",
        "  )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "surprising-range",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:14.838802Z",
          "iopub.status.busy": "2021-06-23T15:57:14.838270Z",
          "iopub.status.idle": "2021-06-23T15:57:14.865368Z",
          "shell.execute_reply": "2021-06-23T15:57:14.864934Z",
          "shell.execute_reply.started": "2021-06-14T10:50:39.080327Z"
        },
        "papermill": {
          "duration": 0.078323,
          "end_time": "2021-06-23T15:57:14.865490",
          "exception": false,
          "start_time": "2021-06-23T15:57:14.787167",
          "status": "completed"
        },
        "tags": [],
        "id": "surprising-range"
      },
      "outputs": [],
      "source": [
        "# check that image has the correct size\n",
        "temp_img, _ =  dataset.__getitem__(0)\n",
        "temp_img.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "grave-acceptance",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:15.068995Z",
          "iopub.status.busy": "2021-06-23T15:57:15.068434Z",
          "iopub.status.idle": "2021-06-23T15:57:15.094488Z",
          "shell.execute_reply": "2021-06-23T15:57:15.094092Z",
          "shell.execute_reply.started": "2021-06-14T10:50:39.100745Z"
        },
        "papermill": {
          "duration": 0.078227,
          "end_time": "2021-06-23T15:57:15.094597",
          "exception": false,
          "start_time": "2021-06-23T15:57:15.016370",
          "status": "completed"
        },
        "tags": [],
        "id": "grave-acceptance"
      },
      "outputs": [],
      "source": [
        "# check that image has the correct normalization\n",
        "temp_img.max(), temp_img.min()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exceptional-mailman",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-13T03:11:55.363449Z",
          "iopub.status.busy": "2021-06-13T03:11:55.363084Z",
          "iopub.status.idle": "2021-06-13T03:11:55.369074Z",
          "shell.execute_reply": "2021-06-13T03:11:55.367783Z",
          "shell.execute_reply.started": "2021-06-13T03:11:55.363409Z"
        },
        "papermill": {
          "duration": 0.047497,
          "end_time": "2021-06-23T15:57:15.189549",
          "exception": false,
          "start_time": "2021-06-23T15:57:15.142052",
          "status": "completed"
        },
        "tags": [],
        "id": "exceptional-mailman"
      },
      "source": [
        "We're going to train using batches of 64 images. This means that our input data will have a shape `(64,1,28,28)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caroline-miami",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:15.288936Z",
          "iopub.status.busy": "2021-06-23T15:57:15.288397Z",
          "iopub.status.idle": "2021-06-23T15:57:15.292247Z",
          "shell.execute_reply": "2021-06-23T15:57:15.291798Z",
          "shell.execute_reply.started": "2021-06-14T10:50:39.110729Z"
        },
        "papermill": {
          "duration": 0.055199,
          "end_time": "2021-06-23T15:57:15.292360",
          "exception": false,
          "start_time": "2021-06-23T15:57:15.237161",
          "status": "completed"
        },
        "tags": [],
        "id": "caroline-miami"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "temp_images, _ = next(iter(dataloader))\n",
        "temp_images.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "studied-signal",
      "metadata": {
        "papermill": {
          "duration": 0.047707,
          "end_time": "2021-06-23T15:57:15.523375",
          "exception": false,
          "start_time": "2021-06-23T15:57:15.475668",
          "status": "completed"
        },
        "tags": [],
        "id": "studied-signal"
      },
      "source": [
        "> Read More\n",
        "1. [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)\n",
        "    - .ToTensor | Convert a PIL Image or numpy.ndarray to tensor. This transform does not support torchscript.\n",
        "    - .ToTensor | Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "presidential-alert",
      "metadata": {
        "papermill": {
          "duration": 0.047404,
          "end_time": "2021-06-23T15:57:15.618538",
          "exception": false,
          "start_time": "2021-06-23T15:57:15.571134",
          "status": "completed"
        },
        "tags": [],
        "id": "presidential-alert"
      },
      "source": [
        "### Step 9. Define optimizers\n",
        "\n",
        "Above we defined the `adversarial_loss`. To train the GAN we need to optimize this objective in two ways:\n",
        "\n",
        "1. Reward the Generator for tricking the Discriminator. The Generator's weights will be tuned accordingly by `optimizer_G`.\n",
        "2. Reward the Discriminator for sussing out the Generator. The Discriminator's weights will be tuned accordingly by `optimizer_D`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "silver-platform",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:15.824835Z",
          "iopub.status.busy": "2021-06-23T15:57:15.823431Z",
          "iopub.status.idle": "2021-06-23T15:57:15.826263Z",
          "shell.execute_reply": "2021-06-23T15:57:15.825745Z",
          "shell.execute_reply.started": "2021-06-14T10:50:39.162408Z"
        },
        "papermill": {
          "duration": 0.055974,
          "end_time": "2021-06-23T15:57:15.826384",
          "exception": false,
          "start_time": "2021-06-23T15:57:15.770410",
          "status": "completed"
        },
        "tags": [],
        "id": "silver-platform"
      },
      "outputs": [],
      "source": [
        "lr = 0.0002\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5,0.999))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5,0.999))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "compressed-southwest",
      "metadata": {
        "papermill": {
          "duration": 0.047834,
          "end_time": "2021-06-23T15:57:15.922701",
          "exception": false,
          "start_time": "2021-06-23T15:57:15.874867",
          "status": "completed"
        },
        "tags": [],
        "id": "compressed-southwest"
      },
      "source": [
        "### Step 10. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "difficult-jurisdiction",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:52:41.513601Z",
          "iopub.status.busy": "2021-06-23T15:52:41.513245Z",
          "iopub.status.idle": "2021-06-23T15:52:42.137653Z",
          "shell.execute_reply": "2021-06-23T15:52:42.136721Z",
          "shell.execute_reply.started": "2021-06-23T15:52:41.513557Z"
        },
        "papermill": {
          "duration": 0.048128,
          "end_time": "2021-06-23T15:57:16.018611",
          "exception": false,
          "start_time": "2021-06-23T15:57:15.970483",
          "status": "completed"
        },
        "tags": [],
        "id": "difficult-jurisdiction"
      },
      "source": [
        "![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpMdme%2FbtqA1ArBCOy%2FqqGg7IvV0hpqVkvBuEFpJK%2Fimg.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gentle-eagle",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:16.118867Z",
          "iopub.status.busy": "2021-06-23T15:57:16.118335Z",
          "iopub.status.idle": "2021-06-23T15:57:16.122355Z",
          "shell.execute_reply": "2021-06-23T15:57:16.121941Z",
          "shell.execute_reply.started": "2021-06-14T10:50:39.171443Z"
        },
        "papermill": {
          "duration": 0.05538,
          "end_time": "2021-06-23T15:57:16.122461",
          "exception": false,
          "start_time": "2021-06-23T15:57:16.067081",
          "status": "completed"
        },
        "tags": [],
        "id": "gentle-eagle"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below you'll see our training loop. The high level structure is:\n",
        "```\n",
        "for each epoch:\n",
        "  for each batch of images:\n",
        "    imgs = batch of images (dim 64x1x784)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "aHVDRV_l32O6"
      },
      "id": "aHVDRV_l32O6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "technical-catering",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T15:57:16.436198Z",
          "iopub.status.busy": "2021-06-23T15:57:16.435641Z",
          "iopub.status.idle": "2021-06-23T16:01:21.638975Z",
          "shell.execute_reply": "2021-06-23T16:01:21.638520Z",
          "shell.execute_reply.started": "2021-06-14T10:50:39.195934Z"
        },
        "papermill": {
          "duration": 245.263847,
          "end_time": "2021-06-23T16:01:21.639099",
          "exception": false,
          "start_time": "2021-06-23T15:57:16.375252",
          "status": "completed"
        },
        "tags": [],
        "id": "technical-catering"
      },
      "outputs": [],
      "source": [
        "n_epochs = 200 # though 200 is recommended in the original tutorial!\n",
        "for epoch in range(n_epochs):\n",
        "    for i, (imgs, _) in enumerate(tqdm(dataloader)):\n",
        "\n",
        "        # truth labels for training\n",
        "        valid = torch.ones(imgs.size(0), 1)\n",
        "        fake = torch.zeros(imgs.size(0), 1)\n",
        "        real_imgs = imgs.type(Tensor) # the images in this batch are all real!\n",
        "\n",
        "        # latent variables z are standard Gaussian variables (64x100)\n",
        "        z = Tensor(np.random.normal(0, 1, (imgs.shape[0],latent_dim)))\n",
        "\n",
        "        # ship everything to GPU if applicable\n",
        "        if cuda:\n",
        "          valid, fake, z = valid.cuda(), fake.cuda(), z.cuda()\n",
        "\n",
        "        ### --- train the generator --- ###\n",
        "\n",
        "        # clear out the gradients from the previous batch\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # ask generator to produce fake images\n",
        "        gen_imgs = generator(z) # outputs (64x1x28x28)\n",
        "\n",
        "        # ask the discriminator to classify the images\n",
        "        d_pred = discriminator(gen_imgs)\n",
        "\n",
        "        # penalize the generator where the discriminator isn't tricked\n",
        "        g_loss = adversarial_loss(d_pred, valid)\n",
        "\n",
        "        # gradient descent to update the generator weights\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        ### --- train the discriminator --- ###\n",
        "\n",
        "        # clear the gradients from the previous batch\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        #  ask the discriminator to classisfy the real images (all valid)\n",
        "        d_pred_real = discriminator(real_imgs)\n",
        "        real_loss = adversarial_loss(d_pred_real, valid)\n",
        "\n",
        "        # ask the discriminator to classify the Generator images (all fake)\n",
        "        d_pred_fake = discriminator(gen_imgs.detach()) # detach the gradient (removes dependence on Generator)\n",
        "        fake_loss = adversarial_loss(d_pred_fake, fake)\n",
        "\n",
        "        # average the loss incurred in both cases\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        # gradient descent to update hte weights\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        ### --- real-time visualization --- ###\n",
        "        sample_z_in_train = Tensor(np.random.normal(0, 1, (imgs.shape[0],latent_dim)))\n",
        "        sample_gen_imgs_in_train = generator(sample_z_in_train).detach().cpu()\n",
        "        if ((i+1) % 200) == 0:\n",
        "            nrows, ncols=1, 5\n",
        "            fig, axes = plt.subplots(nrows=nrows,ncols=ncols, figsize=(8,2))\n",
        "            plt.suptitle('EPOCH : {} | BATCH(ITERATION) : {}'.format(epoch+1, i+1))\n",
        "            for ncol in range(ncols):\n",
        "                axes[ncol].imshow(sample_gen_imgs_in_train.permute(0,2,3,1)[ncol], cmap='gray')\n",
        "                axes[ncol].axis('off')\n",
        "            plt.show()\n",
        "\n",
        "    print(\n",
        "        \"[Epoch: %d/%d] [Batch: %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "        % (epoch+1, n_epochs, i+1, len(dataloader), d_loss.item(), g_loss.item())\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hungarian-carter",
      "metadata": {
        "papermill": {
          "duration": 0.093458,
          "end_time": "2021-06-23T16:01:21.826407",
          "exception": false,
          "start_time": "2021-06-23T16:01:21.732949",
          "status": "completed"
        },
        "tags": [],
        "id": "hungarian-carter"
      },
      "source": [
        "> TEST CODE : enumerate >> [docs.python.org/enumerate](https://docs.python.org/3/library/functions.html#enumerate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "optimum-cameroon",
      "metadata": {
        "papermill": {
          "duration": 0.101571,
          "end_time": "2021-06-23T16:01:37.524745",
          "exception": false,
          "start_time": "2021-06-23T16:01:37.423174",
          "status": "completed"
        },
        "tags": [],
        "id": "optimum-cameroon"
      },
      "source": [
        "## Solutions to Exercises\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1**\n",
        "Try instantiating a generator.\n",
        "Print it out and study the dimensions.\n",
        "Do they make sense? What is the dimension of the output of the generator?\n",
        "```\n",
        "# study the generator\n",
        "g = Generator()\n",
        "print(g)\n",
        "\n",
        "# latent variables to feed the generator\n",
        "g.eval()\n",
        "z = torch.normal(mean=0, std=1, size=(1,100))\n",
        "output = g(z)\n",
        "print(output.shape)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "GJY1BdgbCXig"
      },
      "id": "GJY1BdgbCXig"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2**\n",
        "Try instantiating a discriminator. Print it out and study the dimensions. Do they make sense? What is the dimension of the output of the discriminator?\n",
        "```\n",
        "# study the generator\n",
        "d = Discriminator()\n",
        "print(d)\n",
        "\n",
        "# latent variables to feed the generator\n",
        "d.eval()\n",
        "img = torch.normal(mean=0, std=1, size=(1,1,28,28))\n",
        "pred = d(img)**bold text**\n",
        "print(pred, pred.shape)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "BR0GoEylDZVS"
      },
      "id": "BR0GoEylDZVS"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBWcuMqwCVBa"
      },
      "id": "YBWcuMqwCVBa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ordinary-frame",
      "metadata": {
        "papermill": {
          "duration": 0.101557,
          "end_time": "2021-06-23T16:01:37.728722",
          "exception": false,
          "start_time": "2021-06-23T16:01:37.627165",
          "status": "completed"
        },
        "tags": [],
        "id": "ordinary-frame"
      },
      "source": [
        "--------------"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 286.978272,
      "end_time": "2021-06-23T16:01:39.946658",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-06-23T15:56:52.968386",
      "version": "2.3.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}