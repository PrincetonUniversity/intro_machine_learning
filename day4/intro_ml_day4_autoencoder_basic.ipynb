{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6c58714b",
      "metadata": {
        "papermill": {
          "duration": 0.018496,
          "end_time": "2021-12-30T22:43:39.316122",
          "exception": false,
          "start_time": "2021-12-30T22:43:39.297626",
          "status": "completed"
        },
        "tags": [],
        "id": "6c58714b"
      },
      "source": [
        "# Introduction to Autoencoders\n",
        "\n",
        "This notebook is based on the [Kaggle notebook by Simon Crase](https://www.kaggle.com/code/weka511/autoencoder-implementation-in-pytorch).\n",
        "\n",
        "An autoencoder is a neural network which is trained to reproduce its input. As the figure shows, the layers are successively shorter, until they reach a minimum, then they increase again. Data flows from left to right, and we train so the rightmost layer matches the leftmost, as closely as possible. *If we can make this work,* then the middle layer or \"bottleneck\" layer (labelled Feature) must somehow contain essentially the same information as the two outermost layers: we call the middle layer the *encoding*: it divides the network into two parts, the *encoder*, on the left, and the *decoder* on the right.\n",
        "\n",
        "![Autoencoder schematic](https://www.mdpi.com/IoT/IoT-04-00016/article_deploy/html/images/IoT-04-00016-g001.png)\n",
        "\n",
        "The loss function in this case is the identity function: $MSE = \\sum (x_i - \\hat{x_i})^2$\n",
        "\n",
        "The [manifold hypothesis](https://en.wikipedia.org/wiki/Manifold_hypothesis) asserts that many high-dimensional data sets that occur in the real world actually lie along low-dimensional manifolds inside that high-dimensional space. If we accept that the manifold hypothesis is correct, then it seems reasonable that we can infer the lower dimensional representation of the data, which is what the Autoencoder actually does.\n",
        "\n",
        "## References\n",
        "\n",
        "1. [Implementing an Autoencoder in PyTorch--Abien Fred Agarap](https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccee422c",
      "metadata": {
        "papermill": {
          "duration": 0.017224,
          "end_time": "2021-12-30T22:43:39.350713",
          "exception": false,
          "start_time": "2021-12-30T22:43:39.333489",
          "status": "completed"
        },
        "tags": [],
        "id": "ccee422c"
      },
      "source": [
        "# Import functions from libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe579650",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-30T22:43:39.391673Z",
          "iopub.status.busy": "2021-12-30T22:43:39.390399Z",
          "iopub.status.idle": "2021-12-30T22:43:40.972563Z",
          "shell.execute_reply": "2021-12-30T22:43:40.971145Z",
          "shell.execute_reply.started": "2021-11-19T23:42:44.210602Z"
        },
        "papermill": {
          "duration": 1.602449,
          "end_time": "2021-12-30T22:43:40.972781",
          "exception": false,
          "start_time": "2021-12-30T22:43:39.370332",
          "status": "completed"
        },
        "tags": [],
        "id": "fe579650"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot      import close, figure, imshow, savefig, show, title\n",
        "from matplotlib.lines       import Line2D\n",
        "from os.path                import join\n",
        "from random                 import sample\n",
        "from re                     import split\n",
        "from torch                  import device, no_grad\n",
        "from torch.cuda             import is_available\n",
        "from torch.nn               import Linear, Module, MSELoss, ReLU, Sequential, Sigmoid\n",
        "from torch.optim            import Adam\n",
        "from torch.utils.data       import DataLoader\n",
        "from torchvision.datasets   import MNIST\n",
        "from torchvision.transforms import Compose, ToTensor\n",
        "from torchvision.utils      import make_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e0c4251",
      "metadata": {
        "papermill": {
          "duration": 0.016832,
          "end_time": "2021-12-30T22:43:41.006702",
          "exception": false,
          "start_time": "2021-12-30T22:43:40.989870",
          "status": "completed"
        },
        "tags": [],
        "id": "9e0c4251"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "The learning rate was optimized by trial and error. The error rates are plotted here [here](https://github.com/weka511/learn/issues/26)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37af4dcd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-30T22:43:41.044973Z",
          "iopub.status.busy": "2021-12-30T22:43:41.044147Z",
          "iopub.status.idle": "2021-12-30T22:43:41.048047Z",
          "shell.execute_reply": "2021-12-30T22:43:41.048654Z",
          "shell.execute_reply.started": "2021-11-19T23:42:45.642145Z"
        },
        "papermill": {
          "duration": 0.024988,
          "end_time": "2021-12-30T22:43:41.048857",
          "exception": false,
          "start_time": "2021-12-30T22:43:41.023869",
          "status": "completed"
        },
        "tags": [],
        "id": "37af4dcd"
      },
      "outputs": [],
      "source": [
        "ENCODER = [28*28,400,200,100,50,25,6]  # sizes of encoder layers\n",
        "DECODER = []                           # Decoder layers will be a mirror image of encoder\n",
        "LR      = 0.001                        # Learning rate\n",
        "N       = 12                           # Number of epochs (consider using 32 if using a GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e817b0",
      "metadata": {
        "papermill": {
          "duration": 0.017478,
          "end_time": "2021-12-30T22:43:41.084165",
          "exception": false,
          "start_time": "2021-12-30T22:43:41.066687",
          "status": "completed"
        },
        "tags": [],
        "id": "01e817b0"
      },
      "source": [
        "# The Autoencoder class\n",
        "\n",
        "The AE class is defined below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f6388d0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-30T22:43:41.122575Z",
          "iopub.status.busy": "2021-12-30T22:43:41.121365Z",
          "iopub.status.idle": "2021-12-30T22:43:41.139365Z",
          "shell.execute_reply": "2021-12-30T22:43:41.138701Z",
          "shell.execute_reply.started": "2021-11-19T23:42:45.648846Z"
        },
        "papermill": {
          "duration": 0.038276,
          "end_time": "2021-12-30T22:43:41.139554",
          "exception": false,
          "start_time": "2021-12-30T22:43:41.101278",
          "status": "completed"
        },
        "tags": [],
        "id": "6f6388d0"
      },
      "outputs": [],
      "source": [
        "class AutoEncoder(Module):\n",
        "    '''A class that implements an AutoEncoder\n",
        "    '''\n",
        "    @staticmethod\n",
        "    def get_non_linearity(params):\n",
        "        '''Determine which non linearity is to be used for both encoder and decoder'''\n",
        "        def get_one(param):\n",
        "            '''Determine which non linearity is to be used for either encoder or decoder'''\n",
        "            param = param.lower()\n",
        "            if param=='relu': return ReLU()\n",
        "            if param=='sigmoid': return Sigmoid()\n",
        "            return None\n",
        "\n",
        "        decoder_non_linearity = get_one(params[0])\n",
        "        encoder_non_linearity = getnl(params[a]) if len(params)>1 else decoder_non_linearity\n",
        "\n",
        "        return encoder_non_linearity,decoder_non_linearity\n",
        "\n",
        "    @staticmethod\n",
        "    def build_layer(sizes,\n",
        "                    non_linearity = None):\n",
        "        '''Construct encoder or decoder as a Sequential of Linear labels, with or without non-linearities\n",
        "\n",
        "        Positional arguments:\n",
        "            sizes   List of sizes for each Linear Layer\n",
        "        Keyword arguments:\n",
        "            non_linearity  Object used to introduce non-linearity between layers\n",
        "        '''\n",
        "        linears = [Linear(m,n) for m,n in zip(sizes[:-1],sizes[1:])]\n",
        "        if non_linearity==None:\n",
        "            return Sequential(*linears)\n",
        "        else:\n",
        "            return Sequential(*[item for pair in [(layer,non_linearity) for layer in linears] for item in pair])\n",
        "\n",
        "    def __init__(self,\n",
        "                 encoder_sizes         = [28*28,400,200,100,50,25,6],\n",
        "                 encoder_non_linearity = ReLU(inplace=True),\n",
        "                 decoder_sizes         = [],\n",
        "                 decoder_non_linearity = ReLU(inplace=True)):\n",
        "        '''\n",
        "        Keyword arguments:\n",
        "            encoder_sizes            List of sizes for each Linear Layer in encoder\n",
        "            encoder_non_linearity    Object used to introduce non-linearity between encoder layers\n",
        "            decoder_sizes            List of sizes for each Linear Layer in decoder\n",
        "            decoder_non_linearity    Object used to introduce non-linearity between decoder layers\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.encoder_sizes = encoder_sizes\n",
        "        self.decoder_sizes = encoder_sizes[::-1] if len(decoder_sizes)==0 else decoder_sizes\n",
        "\n",
        "\n",
        "        self.encoder = AutoEncoder.build_layer(self.encoder_sizes,\n",
        "                                               non_linearity = encoder_non_linearity)\n",
        "        self.decoder = AutoEncoder.build_layer(self.decoder_sizes,\n",
        "                                               non_linearity = decoder_non_linearity)\n",
        "        self.encode  = True\n",
        "        self.decode  = True\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''Propagate value through network\n",
        "\n",
        "           Computation is controlled by self.encode and self.decode\n",
        "        '''\n",
        "        if self.encode:\n",
        "            x = self.encoder(x)\n",
        "\n",
        "        if self.decode:\n",
        "            x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "    def n_encoded(self):\n",
        "        return self.encoder_sizes[-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a9312a",
      "metadata": {
        "papermill": {
          "duration": 0.01699,
          "end_time": "2021-12-30T22:43:41.173801",
          "exception": false,
          "start_time": "2021-12-30T22:43:41.156811",
          "status": "completed"
        },
        "tags": [],
        "id": "c0a9312a"
      },
      "source": [
        "# Function to train network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f1b0061",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-30T22:43:41.217948Z",
          "iopub.status.busy": "2021-12-30T22:43:41.216929Z",
          "iopub.status.idle": "2021-12-30T22:43:41.219319Z",
          "shell.execute_reply": "2021-12-30T22:43:41.219855Z",
          "shell.execute_reply.started": "2021-11-19T23:42:45.668529Z"
        },
        "papermill": {
          "duration": 0.028989,
          "end_time": "2021-12-30T22:43:41.220059",
          "exception": false,
          "start_time": "2021-12-30T22:43:41.191070",
          "status": "completed"
        },
        "tags": [],
        "id": "2f1b0061"
      },
      "outputs": [],
      "source": [
        "def train(loader,model,optimizer,criterion,\n",
        "          N   = 25,\n",
        "          dev = 'cpu'):\n",
        "    '''Train network\n",
        "\n",
        "       Parameters:\n",
        "           loader       Used to get data\n",
        "           model        Model to be trained\n",
        "           optimizer    Used to minimze errors\n",
        "           criterion    Used to compute errors\n",
        "      Keyword parameters:\n",
        "          N             Number of epochs\n",
        "          dev           Device - cpu or cuda\n",
        "    '''\n",
        "    Losses        = []\n",
        "\n",
        "    for epoch in range(N):\n",
        "        loss = 0\n",
        "        for batch_features, _ in loader:\n",
        "            batch_features = batch_features.view(-1, 784).to(dev)\n",
        "            optimizer.zero_grad()\n",
        "            outputs        = model(batch_features)\n",
        "            train_loss     = criterion(outputs, batch_features)\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "            loss += train_loss.item()\n",
        "\n",
        "        Losses.append(loss / len(loader))\n",
        "        print(f'epoch : {epoch+1}/{N}, loss = {Losses[-1]:.6f}')\n",
        "\n",
        "    return Losses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ab535a0",
      "metadata": {
        "papermill": {
          "duration": 0.016909,
          "end_time": "2021-12-30T22:43:41.254702",
          "exception": false,
          "start_time": "2021-12-30T22:43:41.237793",
          "status": "completed"
        },
        "tags": [],
        "id": "3ab535a0"
      },
      "source": [
        "# Initialize network and data, and prepare to train\n",
        "\n",
        "This is proably a suboptimal way to load the MNIST dataset, but it will do for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b39298ab",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-30T22:43:41.292998Z",
          "iopub.status.busy": "2021-12-30T22:43:41.292308Z",
          "iopub.status.idle": "2021-12-30T22:43:46.071273Z",
          "shell.execute_reply": "2021-12-30T22:43:46.071869Z",
          "shell.execute_reply.started": "2021-11-19T23:42:45.683478Z"
        },
        "papermill": {
          "duration": 4.800458,
          "end_time": "2021-12-30T22:43:46.072106",
          "exception": false,
          "start_time": "2021-12-30T22:43:41.271648",
          "status": "completed"
        },
        "tags": [],
        "id": "b39298ab"
      },
      "outputs": [],
      "source": [
        "    dev           = device(\"cuda\" if is_available() else \"cpu\")\n",
        "    encoder_non_linearity,decoder_non_linearity = AutoEncoder.get_non_linearity(['relu'])\n",
        "    model         = AutoEncoder(encoder_sizes         = ENCODER,\n",
        "                                encoder_non_linearity = encoder_non_linearity,\n",
        "                                decoder_non_linearity = decoder_non_linearity,\n",
        "                                decoder_sizes         = DECODER).to(dev)\n",
        "    optimizer     = Adam(model.parameters(),\n",
        "                         lr = LR)\n",
        "    criterion     = MSELoss()\n",
        "    transform     = Compose([ToTensor()])\n",
        "\n",
        "    train_dataset = MNIST(root=\"~/torch_datasets\",\n",
        "                          train     = True,\n",
        "                          transform = transform,\n",
        "                          download  = True)\n",
        "    test_dataset  = MNIST(root=\"~/torch_datasets\",\n",
        "                          train     = False,\n",
        "                          transform = transform,\n",
        "                          download  = True)\n",
        "\n",
        "    train_loader  = DataLoader(train_dataset,\n",
        "                               batch_size  = 128,\n",
        "                               shuffle     = True,\n",
        "                               num_workers = 2)\n",
        "    test_loader   = DataLoader(test_dataset,\n",
        "                               batch_size  = 32,\n",
        "                               shuffle     = False,\n",
        "                               num_workers = 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b5d8036",
      "metadata": {
        "papermill": {
          "duration": 0.0219,
          "end_time": "2021-12-30T22:43:46.117538",
          "exception": false,
          "start_time": "2021-12-30T22:43:46.095638",
          "status": "completed"
        },
        "tags": [],
        "id": "0b5d8036"
      },
      "source": [
        "# Train network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473f13ad",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-30T22:43:46.169350Z",
          "iopub.status.busy": "2021-12-30T22:43:46.168705Z",
          "iopub.status.idle": "2021-12-30T22:50:51.279813Z",
          "shell.execute_reply": "2021-12-30T22:50:51.280576Z",
          "shell.execute_reply.started": "2021-11-19T23:42:47.793314Z"
        },
        "papermill": {
          "duration": 425.140629,
          "end_time": "2021-12-30T22:50:51.280894",
          "exception": false,
          "start_time": "2021-12-30T22:43:46.140265",
          "status": "completed"
        },
        "tags": [],
        "id": "473f13ad"
      },
      "outputs": [],
      "source": [
        "Losses = train(train_loader,model,optimizer,criterion, N=N, dev=dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c48b561",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-30T22:50:51.363900Z",
          "iopub.status.busy": "2021-12-30T22:50:51.363125Z",
          "iopub.status.idle": "2021-12-30T22:50:51.364928Z",
          "shell.execute_reply": "2021-12-30T22:50:51.365443Z",
          "shell.execute_reply.started": "2021-11-19T23:43:34.158124Z"
        },
        "papermill": {
          "duration": 0.051206,
          "end_time": "2021-12-30T22:50:51.365640",
          "exception": false,
          "start_time": "2021-12-30T22:50:51.314434",
          "status": "completed"
        },
        "tags": [],
        "id": "5c48b561"
      },
      "outputs": [],
      "source": [
        "def reconstruct(loader,model,criterion,\n",
        "                N        = 25,\n",
        "                prefix   = 'test',\n",
        "                show     = False,\n",
        "                figs     = './figs',\n",
        "                n_images = -1):\n",
        "    '''Reconstruct images from encoding\n",
        "\n",
        "       Parameters:\n",
        "           loader\n",
        "           model\n",
        "       Keyword Parameters:\n",
        "           N        Number of epochs used for training (used in image title only)\n",
        "           prefix   Prefix file names with this string\n",
        "           show     Used to display images\n",
        "           figs     Directory for storing images\n",
        "    '''\n",
        "\n",
        "    def plot(original=None,decoded=None):\n",
        "        '''Plot original images and decoded images'''\n",
        "        fig = figure(figsize=(10,10))\n",
        "        ax    = fig.subplots(nrows=2)\n",
        "        ax[0].imshow(make_grid(original.view(-1,1,28,28)).permute(1, 2, 0))\n",
        "        ax[0].set_title('Raw images')\n",
        "        scaled_decoded = decoded/decoded.max()\n",
        "        ax[1].imshow(make_grid(scaled_decoded.view(-1,1,28,28)).permute(1, 2, 0))\n",
        "        ax[1].set_title(f'Reconstructed images after {N} epochs')\n",
        "        savefig(join(figs,f'{prefix}-comparison-{i}'))\n",
        "        if not show:\n",
        "            close (fig)\n",
        "\n",
        "    samples = [] if n_images==-1 else sample(range(len(loader)//loader.batch_size),\n",
        "                                             k = n_images)\n",
        "    loss = 0.0\n",
        "    with no_grad():\n",
        "        for i,(batch_features, _) in enumerate(loader):\n",
        "            batch_features = batch_features.view(-1, 784).to(dev)\n",
        "            outputs        = model(batch_features)\n",
        "            test_loss      = criterion(outputs, batch_features)\n",
        "            loss          += test_loss.item()\n",
        "            if len(samples)==0 or i in samples:\n",
        "                plot(original=batch_features.cpu(),\n",
        "                    decoded=outputs.cpu())\n",
        "\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31d3437a",
      "metadata": {
        "papermill": {
          "duration": 0.03099,
          "end_time": "2021-12-30T22:50:51.430004",
          "exception": false,
          "start_time": "2021-12-30T22:50:51.399014",
          "status": "completed"
        },
        "tags": [],
        "id": "31d3437a"
      },
      "source": [
        "# Compare output layer with Inputs, to get an idea of the quality of the encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb3e72ac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-30T22:50:51.496628Z",
          "iopub.status.busy": "2021-12-30T22:50:51.495958Z",
          "iopub.status.idle": "2021-12-30T22:50:56.120491Z",
          "shell.execute_reply": "2021-12-30T22:50:56.121028Z",
          "shell.execute_reply.started": "2021-11-19T23:43:34.173886Z"
        },
        "papermill": {
          "duration": 4.659956,
          "end_time": "2021-12-30T22:50:56.121230",
          "exception": false,
          "start_time": "2021-12-30T22:50:51.461274",
          "status": "completed"
        },
        "tags": [],
        "id": "fb3e72ac"
      },
      "outputs": [],
      "source": [
        "test_loss = reconstruct(test_loader,model,criterion,\n",
        "                            N        = N,\n",
        "                            show     = True,\n",
        "                            figs     = '.',\n",
        "                            n_images = 1,\n",
        "                            prefix   = 'foo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfd134d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-30T22:50:56.233843Z",
          "iopub.status.busy": "2021-12-30T22:50:56.232938Z",
          "iopub.status.idle": "2021-12-30T22:50:56.236451Z",
          "shell.execute_reply": "2021-12-30T22:50:56.235866Z",
          "shell.execute_reply.started": "2021-11-19T23:43:38.680112Z"
        },
        "papermill": {
          "duration": 0.064524,
          "end_time": "2021-12-30T22:50:56.236593",
          "exception": false,
          "start_time": "2021-12-30T22:50:56.172069",
          "status": "completed"
        },
        "tags": [],
        "id": "abfd134d"
      },
      "outputs": [],
      "source": [
        "def plot_losses(Losses,\n",
        "                lr                   = 0.001,\n",
        "                encoder              = [],\n",
        "                decoder              = [],\n",
        "                encoder_nonlinearity = None,\n",
        "                decoder_nonlinearity = None,\n",
        "                N                    = 25,\n",
        "                show                 = False,\n",
        "                figs                 = './figs',\n",
        "                prefix               = 'ae',\n",
        "                test_loss            = 0):\n",
        "    '''Plot curve of training losses'''\n",
        "    fig = figure(figsize=(10,10))\n",
        "    ax  = fig.subplots()\n",
        "    ax.plot(Losses)\n",
        "    ax.set_ylim(bottom=0)\n",
        "    ax.set_title(f'Training Losses after {N} epochs')\n",
        "    ax.set_ylabel('MSELoss')\n",
        "    ax.text(0.95, 0.95, '\\n'.join([f'lr = {lr}',\n",
        "                                   f'encoder = {encoder}',\n",
        "                                   f'decoder = {decoder}',\n",
        "                                   f'encoder nonlinearity = {encoder_nonlinearity}',\n",
        "                                   f'decoder nonlinearity = {decoder_nonlinearity}',\n",
        "                                   f'test loss = {test_loss:.3f}'\n",
        "                                   ]),\n",
        "            transform           = ax.transAxes,\n",
        "            fontsize            = 14,\n",
        "            verticalalignment   = 'top',\n",
        "            horizontalalignment = 'right',\n",
        "            bbox                = dict(boxstyle  = 'round',\n",
        "                                       facecolor = 'wheat',\n",
        "                                       alpha     = 0.5))\n",
        "    savefig(join(figs,f'{prefix}-losses'))\n",
        "    if not show:\n",
        "        close (fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f46bcd0c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-30T22:50:56.344638Z",
          "iopub.status.busy": "2021-12-30T22:50:56.340313Z",
          "iopub.status.idle": "2021-12-30T22:50:56.692322Z",
          "shell.execute_reply": "2021-12-30T22:50:56.692899Z",
          "shell.execute_reply.started": "2021-11-19T23:43:38.694286Z"
        },
        "papermill": {
          "duration": 0.40641,
          "end_time": "2021-12-30T22:50:56.693112",
          "exception": false,
          "start_time": "2021-12-30T22:50:56.286702",
          "status": "completed"
        },
        "tags": [],
        "id": "f46bcd0c"
      },
      "outputs": [],
      "source": [
        "    plot_losses(Losses,\n",
        "                lr                   = LR,\n",
        "                encoder              = model.encoder_sizes,\n",
        "                decoder              = model.decoder_sizes,\n",
        "                encoder_nonlinearity = encoder_non_linearity,\n",
        "                decoder_nonlinearity = decoder_non_linearity,\n",
        "                N                    = N,\n",
        "                show                 = True,\n",
        "                figs                 = '.',\n",
        "                prefix               = 'foo',\n",
        "                test_loss            = test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63740984",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-30T22:50:56.815337Z",
          "iopub.status.busy": "2021-12-30T22:50:56.814270Z",
          "iopub.status.idle": "2021-12-30T22:50:56.817513Z",
          "shell.execute_reply": "2021-12-30T22:50:56.816822Z",
          "shell.execute_reply.started": "2021-11-19T23:43:39.065776Z"
        },
        "papermill": {
          "duration": 0.07216,
          "end_time": "2021-12-30T22:50:56.817683",
          "exception": false,
          "start_time": "2021-12-30T22:50:56.745523",
          "status": "completed"
        },
        "tags": [],
        "id": "63740984"
      },
      "outputs": [],
      "source": [
        "def plot_encoding(loader,model,\n",
        "                figs    = './figs',\n",
        "                dev     = 'cpu',\n",
        "                colours = [],\n",
        "                show    = False,\n",
        "                prefix  = 'ae'):\n",
        "    '''Plot the encoding layer\n",
        "\n",
        "       Since this is multi,dimensional, we will break it into 2D plots\n",
        "    '''\n",
        "    def extract_batch(batch_features, labels,index):\n",
        "        '''Extract xs, ys, and colours for one batch'''\n",
        "\n",
        "        dev = \"cpu\"\n",
        "        batch_features = batch_features.view(-1, 784).to(dev)\n",
        "        model.cpu()\n",
        "        jj = model(batch_features)\n",
        "        encoded        = model(batch_features).tolist()\n",
        "        return list(zip(*([encoded[k][2*index] for k in range(len(labels))],\n",
        "                          [encoded[k][2*index+1] for k in range(len(labels))],\n",
        "                          [colours[labels.tolist()[k]] for k in range(len(labels))])))\n",
        "\n",
        "    save_decode  = model.decode\n",
        "    model.decode = False\n",
        "    with no_grad():\n",
        "        fig     = figure(figsize=(10,10))\n",
        "        ax      = fig.subplots(nrows=2,ncols=2)\n",
        "        for i in range(2):\n",
        "            for j in range(2):\n",
        "                if i==1 and j==1: break\n",
        "                index    = 2*i + j\n",
        "                if 2*index+1 < model.n_encoded():\n",
        "                    xs,ys,cs = tuple(zip(*[xyc for batch_features, labels in loader for xyc in extract_batch(batch_features.cpu(), labels.cpu(),index)]))\n",
        "                    ax[i][j].set_title(f'{2*index}-{2*index+1}')\n",
        "                    ax[i][j].scatter(xs,ys,c=cs,s=1)\n",
        "\n",
        "    ax[0][0].legend(handles=[Line2D([], [],\n",
        "                                    color  = colours[k],\n",
        "                                    marker = 's',\n",
        "                                    ls     = '',\n",
        "                                    label  = f'{k}') for k in range(10)])\n",
        "    savefig(join(figs,f'{prefix}-encoding'))\n",
        "    if not show:\n",
        "        close (fig)\n",
        "\n",
        "    model.decode = save_decode"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62cfabb4",
      "metadata": {
        "papermill": {
          "duration": 0.052065,
          "end_time": "2021-12-30T22:50:56.922239",
          "exception": false,
          "start_time": "2021-12-30T22:50:56.870174",
          "status": "completed"
        },
        "tags": [],
        "id": "62cfabb4"
      },
      "source": [
        "# Plot encoded data\n",
        "\n",
        "The encoding shows that the images for most digits are separated. It also suggests that the encoded data have been made to live in a 5-dimensional manifold instead of needing 6 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf972eef",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-30T22:50:57.099020Z",
          "iopub.status.busy": "2021-12-30T22:50:57.097559Z",
          "iopub.status.idle": "2021-12-30T22:51:04.469870Z",
          "shell.execute_reply": "2021-12-30T22:51:04.470488Z",
          "shell.execute_reply.started": "2021-11-19T23:43:39.08394Z"
        },
        "papermill": {
          "duration": 7.496001,
          "end_time": "2021-12-30T22:51:04.470752",
          "exception": false,
          "start_time": "2021-12-30T22:50:56.974751",
          "status": "completed"
        },
        "tags": [],
        "id": "bf972eef"
      },
      "outputs": [],
      "source": [
        "plot_encoding(test_loader,model,\n",
        "                  show    = True,\n",
        "                  colours = ['xkcd:purple',\n",
        "                             'xkcd:green',\n",
        "                             'xkcd:blue',\n",
        "                             'xkcd:pink',\n",
        "                             'xkcd:brown',\n",
        "                             'xkcd:red',\n",
        "                             'xkcd:magenta',\n",
        "                             'xkcd:yellow',\n",
        "                             'xkcd:light teal',\n",
        "                             'xkcd:puke'],\n",
        "                  figs    = '.',\n",
        "                  prefix  = 'foo')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 455.930421,
      "end_time": "2021-12-30T22:51:05.342165",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-12-30T22:43:29.411744",
      "version": "2.3.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}