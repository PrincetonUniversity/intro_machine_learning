{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMuOi57j8EtrC5kz4UbtZUF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrincetonUniversity/intro_machine_learning/blob/main/day5/natural_language_processing_hackathon/day5_nlp_movie_reviews_notebook2_hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction to Machine Learning  \n",
        "**Natural Language Processing Hackathon: Notebook 2  \n",
        "Wintersession  \n",
        "Tuesday, January 24, 2023**"
      ],
      "metadata": {
        "id": "MH7MrrKyZ3dQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The material here is based on Chapter 8 of \n",
        "Machine Learning with PyTorch and Scikit-Learn by Sebastian Raschka, Yuxi (Hayden) Liu, Vahid Mirjalili and Dmytro Dzhulgakov. The book is available via the PU library.\n",
        "\n",
        "In this notebook we are going to work with a dataset of 50,000 movie reviews from the Internet Movie Database (IMDb) and build a predictor that can distinguish between positive and negative reviews."
      ],
      "metadata": {
        "id": "AcJNrVl84xDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import textwrap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "UuDdLpWUaBRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dowload and View the Data"
      ],
      "metadata": {
        "id": "RFLgSxPO2u-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the data set:"
      ],
      "metadata": {
        "id": "wjO7F84nz99c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoSng-U6VyvC"
      },
      "outputs": [],
      "source": [
        "!wget https://tigress-web.princeton.edu/~jdh4/movie_data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in the CSV file and print the first 5 rows of the Pandas dataframe:"
      ],
      "metadata": {
        "id": "peptRcYAdrSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('movie_data.csv', encoding='utf-8')\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "DuYihEqqcBwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the number of total rows and the data types:"
      ],
      "metadata": {
        "id": "rlcaf5fad1VT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "7tK0-ZCLdQVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check for class imbalance:"
      ],
      "metadata": {
        "id": "js0X9iZkda1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"sentiment\"].value_counts()"
      ],
      "metadata": {
        "id": "yvB3XKdudStC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classes are balanced so we do not need to worry about imbalance. Next, let's print some reviews to get a sense of the content."
      ],
      "metadata": {
        "id": "4uycrR1jeHBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_reviews_and_sentiment(d, start_index=42, num=3, width=80):\n",
        "    wrapper = textwrap.TextWrapper(width=width, break_long_words=False, break_on_hyphens=False)\n",
        "    for i in range(start_index, start_index + num):\n",
        "        print(wrapper.fill(str(d.loc[i][\"review\"])))\n",
        "        print('------------')\n",
        "        print(f'Sentiment: {d.loc[i][\"sentiment\"]}\\n')"
      ],
      "metadata": {
        "id": "NVoLU81BcQtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_reviews_and_sentiment(df, start_index=42, num=2)"
      ],
      "metadata": {
        "id": "cyhpu6ycjSNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hackathon Project"
      ],
      "metadata": {
        "id": "pri7RiNL110z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a classifier on the movie review data. See if you can get about 88% accuracy on the test set that you make. Use the techniques from the previous notebook and previous workshop days."
      ],
      "metadata": {
        "id": "kgu5qQAh15ko"
      }
    }
  ]
}